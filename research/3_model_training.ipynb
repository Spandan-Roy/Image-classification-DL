{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/Personal/projects/vision/Image-classification-DL'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_is_augmentation: bool\n",
    "    params_image_size: list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN_Classifier.constants import *\n",
    "from CNN_Classifier.utils.common import read_yaml,create_directories\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath=CONFIG_FILE_PATH,\n",
    "        params_filepath=PARAMS_FILE_PATH):\n",
    "        \n",
    "        self.config=read_yaml(config_filepath)\n",
    "        self.params=read_yaml(params_filepath)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def get_training_config(self)->TrainingConfig:\n",
    "        training=self.config.training\n",
    "        prepare_base_model=self.config.prepare_base_model\n",
    "        params=self.params\n",
    "        training_data=os.path.join(self.config.data_ingestion.unzip_dir,\"kidney-ct-scan-image\")\n",
    "        create_directories([Path(training.root_dir)])\n",
    "        \n",
    "        training_config=TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE\n",
    "        )\n",
    "        return training_config        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.updated_base_model_path\n",
    "        )\n",
    "\n",
    "    def train_valid_generator(self):\n",
    "\n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale = 1./255,\n",
    "            validation_split=0.20\n",
    "        )\n",
    "\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=self.config.params_image_size[:-1],\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "\n",
    "        self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"validation\",\n",
    "            shuffle=False,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "        if self.config.params_is_augmentation:\n",
    "            train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                rotation_range=40,\n",
    "                horizontal_flip=True,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                **datagenerator_kwargs\n",
    "            )\n",
    "        else:\n",
    "            train_datagenerator = valid_datagenerator\n",
    "\n",
    "        self.train_generator = train_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"training\",\n",
    "            shuffle=True,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        self.steps_per_epoch = self.train_generator.samples // self.train_generator.batch_size\n",
    "        self.validation_steps = self.valid_generator.samples // self.valid_generator.batch_size\n",
    "\n",
    "        self.model.fit(\n",
    "            self.train_generator,\n",
    "            epochs=self.config.params_epochs,\n",
    "            steps_per_epoch=self.steps_per_epoch,\n",
    "            validation_steps=self.validation_steps,\n",
    "            validation_data=self.valid_generator\n",
    "        )\n",
    "\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-20 14:29:15,206: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-12-20 14:29:15,208: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-12-20 14:29:15,208: INFO: common: created directory at: artifacts]\n",
      "[2024-12-20 14:29:15,209: INFO: common: created directory at: artifacts/training]\n",
      "Found 2487 images belonging to 4 classes.\n",
      "Found 9959 images belonging to 4 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 14:29:16.752053: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331/331 [==============================] - ETA: 0s - loss: 15.9827 - accuracy: 0.3743"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 14:30:09.872229: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331/331 [==============================] - 65s 194ms/step - loss: 15.9827 - accuracy: 0.3743 - val_loss: 8.1960 - val_accuracy: 0.1732\n",
      "Epoch 2/30\n",
      "331/331 [==============================] - 67s 201ms/step - loss: 9.4006 - accuracy: 0.4743 - val_loss: 8.1144 - val_accuracy: 0.5720\n",
      "Epoch 3/30\n",
      "331/331 [==============================] - 66s 199ms/step - loss: 5.9271 - accuracy: 0.5646 - val_loss: 7.0244 - val_accuracy: 0.4833\n",
      "Epoch 4/30\n",
      "331/331 [==============================] - 66s 200ms/step - loss: 4.9457 - accuracy: 0.5965 - val_loss: 22.3848 - val_accuracy: 0.4126\n",
      "Epoch 5/30\n",
      "331/331 [==============================] - 67s 202ms/step - loss: 4.6279 - accuracy: 0.6053 - val_loss: 4.4852 - val_accuracy: 0.5671\n",
      "Epoch 6/30\n",
      "331/331 [==============================] - 68s 206ms/step - loss: 3.9808 - accuracy: 0.6407 - val_loss: 6.5752 - val_accuracy: 0.4915\n",
      "Epoch 7/30\n",
      "331/331 [==============================] - 68s 205ms/step - loss: 3.8522 - accuracy: 0.6439 - val_loss: 7.4550 - val_accuracy: 0.3122\n",
      "Epoch 8/30\n",
      "331/331 [==============================] - 75s 226ms/step - loss: 3.9438 - accuracy: 0.6417 - val_loss: 13.9715 - val_accuracy: 0.2354\n",
      "Epoch 9/30\n",
      "331/331 [==============================] - 75s 225ms/step - loss: 3.2982 - accuracy: 0.6758 - val_loss: 6.4543 - val_accuracy: 0.5557\n",
      "Epoch 10/30\n",
      "331/331 [==============================] - 73s 220ms/step - loss: 2.5232 - accuracy: 0.7128 - val_loss: 6.7131 - val_accuracy: 0.6703\n",
      "Epoch 11/30\n",
      "331/331 [==============================] - 74s 223ms/step - loss: 2.7335 - accuracy: 0.7092 - val_loss: 3.3871 - val_accuracy: 0.6325\n",
      "Epoch 12/30\n",
      "331/331 [==============================] - 72s 219ms/step - loss: 2.5968 - accuracy: 0.7108 - val_loss: 3.8209 - val_accuracy: 0.5890\n",
      "Epoch 13/30\n",
      "331/331 [==============================] - 70s 211ms/step - loss: 2.3167 - accuracy: 0.7261 - val_loss: 6.2527 - val_accuracy: 0.5707\n",
      "Epoch 14/30\n",
      "331/331 [==============================] - 71s 213ms/step - loss: 2.5335 - accuracy: 0.7195 - val_loss: 4.9908 - val_accuracy: 0.4110\n",
      "Epoch 15/30\n",
      "331/331 [==============================] - 69s 208ms/step - loss: 2.1565 - accuracy: 0.7393 - val_loss: 7.8678 - val_accuracy: 0.5163\n",
      "Epoch 16/30\n",
      "331/331 [==============================] - 69s 209ms/step - loss: 2.0800 - accuracy: 0.7399 - val_loss: 4.4458 - val_accuracy: 0.6732\n",
      "Epoch 17/30\n",
      "331/331 [==============================] - 68s 206ms/step - loss: 2.2096 - accuracy: 0.7335 - val_loss: 2.7188 - val_accuracy: 0.5947\n",
      "Epoch 18/30\n",
      "331/331 [==============================] - 66s 200ms/step - loss: 1.9291 - accuracy: 0.7513 - val_loss: 3.0741 - val_accuracy: 0.6841\n",
      "Epoch 19/30\n",
      "331/331 [==============================] - 65s 195ms/step - loss: 2.1656 - accuracy: 0.7397 - val_loss: 4.5736 - val_accuracy: 0.5390\n",
      "Epoch 20/30\n",
      "331/331 [==============================] - 63s 191ms/step - loss: 1.7335 - accuracy: 0.7693 - val_loss: 3.3080 - val_accuracy: 0.6419\n",
      "Epoch 21/30\n",
      "331/331 [==============================] - 65s 195ms/step - loss: 1.7229 - accuracy: 0.7663 - val_loss: 2.5562 - val_accuracy: 0.6374\n",
      "Epoch 22/30\n",
      "331/331 [==============================] - 64s 193ms/step - loss: 1.7209 - accuracy: 0.7747 - val_loss: 2.7126 - val_accuracy: 0.6382\n",
      "Epoch 23/30\n",
      "331/331 [==============================] - 65s 195ms/step - loss: 2.2589 - accuracy: 0.7423 - val_loss: 3.0785 - val_accuracy: 0.6179\n",
      "Epoch 24/30\n",
      "331/331 [==============================] - 64s 193ms/step - loss: 1.3608 - accuracy: 0.7990 - val_loss: 3.2036 - val_accuracy: 0.6480\n",
      "Epoch 25/30\n",
      "331/331 [==============================] - 63s 191ms/step - loss: 1.4241 - accuracy: 0.7959 - val_loss: 2.8368 - val_accuracy: 0.6394\n",
      "Epoch 26/30\n",
      "331/331 [==============================] - 63s 191ms/step - loss: 1.5805 - accuracy: 0.7851 - val_loss: 3.2539 - val_accuracy: 0.6256\n",
      "Epoch 27/30\n",
      "331/331 [==============================] - 63s 191ms/step - loss: 1.4052 - accuracy: 0.7870 - val_loss: 4.5015 - val_accuracy: 0.5341\n",
      "Epoch 28/30\n",
      "331/331 [==============================] - 64s 192ms/step - loss: 1.4011 - accuracy: 0.7948 - val_loss: 3.2974 - val_accuracy: 0.5301\n",
      "Epoch 29/30\n",
      "331/331 [==============================] - 63s 191ms/step - loss: 1.4077 - accuracy: 0.7956 - val_loss: 2.6796 - val_accuracy: 0.6228\n",
      "Epoch 30/30\n",
      "331/331 [==============================] - 65s 195ms/step - loss: 1.1639 - accuracy: 0.8139 - val_loss: 8.2125 - val_accuracy: 0.3618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spandy/miniforge3/envs/vision/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train()\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
