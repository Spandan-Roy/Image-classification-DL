{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"Image-classification-DL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/Personal/projects/vision/Image-classification-DL'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_is_augmentation: bool\n",
    "    params_image_size: list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN_Classifier.constants import *\n",
    "from CNN_Classifier.utils.common import read_yaml,create_directories\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath=CONFIG_FILE_PATH,\n",
    "        params_filepath=PARAMS_FILE_PATH):\n",
    "        \n",
    "        self.config=read_yaml(config_filepath)\n",
    "        self.params=read_yaml(params_filepath)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def get_training_config(self)->TrainingConfig:\n",
    "        training=self.config.training\n",
    "        prepare_base_model=self.config.prepare_base_model\n",
    "        params=self.params\n",
    "        training_data=os.path.join(self.config.data_ingestion.unzip_dir,\"kidney-ct-scan-image\")\n",
    "        create_directories([Path(training.root_dir)])\n",
    "        \n",
    "        training_config=TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE\n",
    "        )\n",
    "        return training_config        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.updated_base_model_path\n",
    "        )\n",
    "\n",
    "    def train_valid_generator(self):\n",
    "\n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale = 1./255,\n",
    "            validation_split=0.20\n",
    "        )\n",
    "\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=self.config.params_image_size[:-1],\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "\n",
    "        self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"validation\",\n",
    "            shuffle=False,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "        if self.config.params_is_augmentation:\n",
    "            train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                rotation_range=40,\n",
    "                horizontal_flip=True,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                **datagenerator_kwargs\n",
    "            )\n",
    "        else:\n",
    "            train_datagenerator = valid_datagenerator\n",
    "\n",
    "        self.train_generator = train_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"training\",\n",
    "            shuffle=True,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        self.steps_per_epoch = self.train_generator.samples // self.train_generator.batch_size\n",
    "        self.validation_steps = self.valid_generator.samples // self.valid_generator.batch_size\n",
    "\n",
    "        self.model.fit(\n",
    "            self.train_generator,\n",
    "            epochs=self.config.params_epochs,\n",
    "            steps_per_epoch=self.steps_per_epoch,\n",
    "            validation_steps=self.validation_steps,\n",
    "            validation_data=self.valid_generator\n",
    "        )\n",
    "\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-20 18:32:31,589: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-12-20 18:32:31,591: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-12-20 18:32:31,592: INFO: common: created directory at: artifacts]\n",
      "[2024-12-20 18:32:31,592: INFO: common: created directory at: artifacts/training]\n",
      "Found 2487 images belonging to 4 classes.\n",
      "Found 9959 images belonging to 4 classes.\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 18:32:32.810987: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - ETA: 0s - loss: 4.2201 - accuracy: 0.6289"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 18:33:26.038313: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 65s 639ms/step - loss: 4.2201 - accuracy: 0.6289 - val_loss: 2.6380 - val_accuracy: 0.4533\n",
      "Epoch 2/40\n",
      "99/99 [==============================] - 67s 672ms/step - loss: 1.0940 - accuracy: 0.7592 - val_loss: 2.5740 - val_accuracy: 0.5713\n",
      "Epoch 3/40\n",
      "99/99 [==============================] - 65s 654ms/step - loss: 0.8724 - accuracy: 0.8017 - val_loss: 2.9461 - val_accuracy: 0.5642\n",
      "Epoch 4/40\n",
      "99/99 [==============================] - 65s 651ms/step - loss: 0.7326 - accuracy: 0.8428 - val_loss: 2.9595 - val_accuracy: 0.5671\n",
      "Epoch 5/40\n",
      "99/99 [==============================] - 65s 649ms/step - loss: 0.9850 - accuracy: 0.8170 - val_loss: 2.9586 - val_accuracy: 0.6500\n",
      "Epoch 6/40\n",
      "99/99 [==============================] - 65s 651ms/step - loss: 0.6528 - accuracy: 0.8654 - val_loss: 3.3770 - val_accuracy: 0.6237\n",
      "Epoch 7/40\n",
      "99/99 [==============================] - 65s 654ms/step - loss: 0.5783 - accuracy: 0.8782 - val_loss: 2.9302 - val_accuracy: 0.6717\n",
      "Epoch 8/40\n",
      "99/99 [==============================] - 65s 658ms/step - loss: 0.6192 - accuracy: 0.8812 - val_loss: 4.4741 - val_accuracy: 0.5471\n",
      "Epoch 9/40\n",
      "99/99 [==============================] - 65s 649ms/step - loss: 0.6431 - accuracy: 0.8782 - val_loss: 3.5171 - val_accuracy: 0.6383\n",
      "Epoch 10/40\n",
      "99/99 [==============================] - 66s 666ms/step - loss: 0.6756 - accuracy: 0.8731 - val_loss: 4.0289 - val_accuracy: 0.6792\n",
      "Epoch 11/40\n",
      "99/99 [==============================] - 64s 646ms/step - loss: 1.1763 - accuracy: 0.8461 - val_loss: 4.0382 - val_accuracy: 0.6333\n",
      "Epoch 12/40\n",
      "99/99 [==============================] - 64s 646ms/step - loss: 1.2325 - accuracy: 0.8608 - val_loss: 5.1303 - val_accuracy: 0.5713\n",
      "Epoch 13/40\n",
      "99/99 [==============================] - 64s 644ms/step - loss: 0.7315 - accuracy: 0.8864 - val_loss: 3.9524 - val_accuracy: 0.6504\n",
      "Epoch 14/40\n",
      "99/99 [==============================] - 66s 659ms/step - loss: 0.7036 - accuracy: 0.8928 - val_loss: 5.4154 - val_accuracy: 0.6288\n",
      "Epoch 15/40\n",
      "99/99 [==============================] - 63s 637ms/step - loss: 0.5947 - accuracy: 0.9052 - val_loss: 4.6782 - val_accuracy: 0.6667\n",
      "Epoch 16/40\n",
      "99/99 [==============================] - 63s 630ms/step - loss: 0.5592 - accuracy: 0.9102 - val_loss: 4.5657 - val_accuracy: 0.7142\n",
      "Epoch 17/40\n",
      "99/99 [==============================] - 63s 636ms/step - loss: 0.7071 - accuracy: 0.8947 - val_loss: 5.6600 - val_accuracy: 0.5362\n",
      "Epoch 18/40\n",
      "99/99 [==============================] - 63s 633ms/step - loss: 0.9471 - accuracy: 0.8823 - val_loss: 7.4917 - val_accuracy: 0.6458\n",
      "Epoch 19/40\n",
      "99/99 [==============================] - 63s 635ms/step - loss: 0.7415 - accuracy: 0.8989 - val_loss: 7.3749 - val_accuracy: 0.6137\n",
      "Epoch 20/40\n",
      "99/99 [==============================] - 63s 634ms/step - loss: 0.6434 - accuracy: 0.9084 - val_loss: 5.4443 - val_accuracy: 0.6050\n",
      "Epoch 21/40\n",
      "99/99 [==============================] - 65s 649ms/step - loss: 0.5668 - accuracy: 0.9152 - val_loss: 5.1820 - val_accuracy: 0.6925\n",
      "Epoch 22/40\n",
      "99/99 [==============================] - 65s 658ms/step - loss: 0.6735 - accuracy: 0.9077 - val_loss: 7.3037 - val_accuracy: 0.5396\n",
      "Epoch 23/40\n",
      "99/99 [==============================] - 63s 637ms/step - loss: 0.6017 - accuracy: 0.9110 - val_loss: 5.7282 - val_accuracy: 0.6762\n",
      "Epoch 24/40\n",
      "99/99 [==============================] - 63s 633ms/step - loss: 0.6483 - accuracy: 0.9133 - val_loss: 5.2345 - val_accuracy: 0.6829\n",
      "Epoch 25/40\n",
      "99/99 [==============================] - 63s 634ms/step - loss: 0.6050 - accuracy: 0.9174 - val_loss: 6.0396 - val_accuracy: 0.6308\n",
      "Epoch 26/40\n",
      "99/99 [==============================] - 63s 632ms/step - loss: 0.8197 - accuracy: 0.8984 - val_loss: 6.9870 - val_accuracy: 0.6567\n",
      "Epoch 27/40\n",
      "99/99 [==============================] - 63s 632ms/step - loss: 0.6216 - accuracy: 0.9215 - val_loss: 8.0528 - val_accuracy: 0.5408\n",
      "Epoch 28/40\n",
      "99/99 [==============================] - 63s 631ms/step - loss: 1.0779 - accuracy: 0.8905 - val_loss: 7.1286 - val_accuracy: 0.7067\n",
      "Epoch 29/40\n",
      "99/99 [==============================] - 63s 636ms/step - loss: 0.5342 - accuracy: 0.9316 - val_loss: 5.3290 - val_accuracy: 0.6783\n",
      "Epoch 30/40\n",
      "99/99 [==============================] - 63s 634ms/step - loss: 0.6689 - accuracy: 0.9131 - val_loss: 6.0376 - val_accuracy: 0.6679\n",
      "Epoch 31/40\n",
      "99/99 [==============================] - 63s 632ms/step - loss: 0.9222 - accuracy: 0.8983 - val_loss: 6.6111 - val_accuracy: 0.6933\n",
      "Epoch 32/40\n",
      "99/99 [==============================] - 64s 641ms/step - loss: 0.6453 - accuracy: 0.9213 - val_loss: 7.0374 - val_accuracy: 0.6583\n",
      "Epoch 33/40\n",
      "99/99 [==============================] - 64s 647ms/step - loss: 0.7706 - accuracy: 0.9131 - val_loss: 8.4966 - val_accuracy: 0.5479\n",
      "Epoch 34/40\n",
      "99/99 [==============================] - 64s 641ms/step - loss: 0.6962 - accuracy: 0.9198 - val_loss: 7.0376 - val_accuracy: 0.6229\n",
      "Epoch 35/40\n",
      "99/99 [==============================] - 64s 638ms/step - loss: 0.7200 - accuracy: 0.9202 - val_loss: 11.0592 - val_accuracy: 0.4825\n",
      "Epoch 36/40\n",
      "99/99 [==============================] - 63s 633ms/step - loss: 0.5269 - accuracy: 0.9343 - val_loss: 8.5882 - val_accuracy: 0.6433\n",
      "Epoch 37/40\n",
      "99/99 [==============================] - 64s 643ms/step - loss: 0.5716 - accuracy: 0.9289 - val_loss: 8.7862 - val_accuracy: 0.6687\n",
      "Epoch 38/40\n",
      "99/99 [==============================] - 65s 654ms/step - loss: 0.5644 - accuracy: 0.9300 - val_loss: 6.5642 - val_accuracy: 0.7083\n",
      "Epoch 39/40\n",
      "99/99 [==============================] - 65s 651ms/step - loss: 0.5431 - accuracy: 0.9309 - val_loss: 7.0917 - val_accuracy: 0.6604\n",
      "Epoch 40/40\n",
      "99/99 [==============================] - 65s 651ms/step - loss: 0.7583 - accuracy: 0.9153 - val_loss: 7.2943 - val_accuracy: 0.6375\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train()\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
